I"$<h4 id="论文信息">论文信息</h4>

<blockquote>
  <p>题名: Pivot-based Transfer Learning for Neural Machine Translation between Non-English Languages</p>

  <p>来源: EMNLP</p>

  <p>年份: 2019</p>

  <p>学习原因: 学习AAAI2020的那篇迁移学习有提到</p>
</blockquote>

<ul>
  <li>
    <h5 id="1-abstract"><a href="#1">1 Abstract</a></h5>
  </li>
  <li>
    <h5 id="2-introduction"><a href="#2">2 Introduction</a></h5>
  </li>
  <li>
    <h5 id="3-method"><a href="#3">3 Method</a></h5>
  </li>
  <li>
    <h5 id="4-experiments"><a href="#4">4 Experiments</a></h5>
  </li>
  <li>
    <h5 id="5-conclusions--contibutions"><a href="#5">5 Conclusions &amp; Contibutions</a></h5>
  </li>
</ul>

<hr />

<h4 id="1">摘要</h4>
<p>改进了低资源语言迁移学习的方法，提出了三种新的基于Pivot的迁移学习方法。</p>

<p>(<code class="language-plaintext highlighter-rouge">标题看见non-english以为终于遇见以中文为研究对象的pivot-based的方法了，但其实不是。这里的non-english主要是想表明除了英文以外的语言没有大量的语料</code>)</p>

<p><br /></p>

<h4 id="2">Introduction</h4>
<p>作者提出，pivot-based的翻译方法有两个很明显的缺点：</p>

<p>1.解码时间为直接翻译的两倍。</p>

<p>2.生成的错误会在pivoting的过程中传播。</p>

<p>所以作者认为还是直接建立source→target的翻译模型比较好。（<code class="language-plaintext highlighter-rouge">显而易见</code>）</p>

<p>相关工作：</p>

<p>1.基于pivot方法合成语料。(<code class="language-plaintext highlighter-rouge">下次会看这一篇</code>)</p>

<p>2.多语言翻译模型训练。</p>

<p>作者相应的也通过迁移学习的思想，创建了一个直接的nmt模型。（<code class="language-plaintext highlighter-rouge">虽然使用了pivot的方法，但并不是pivot直接对语料进行翻译训练，而是进行参数拷贝，所以作者认为根本上还是一个直接的模型吧</code>）。</p>

<hr />

<p>相关概念：</p>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">pivot translation</code>(pivoting)</p>

    <p>就是普通的source→pivot,pivot→target这样翻译。</p>
  </li>
  <li>
    <p>利用pivot-based方法合成平行语料。</p>

    <p>(之后看)</p>
  </li>
  <li>
    <p>pivot-based模型训练。</p>

    <p>基于source→pivot模型与pivot→target模型的特征训练source→target模型。</p>

    <p>作者也是用的这种方法进行迁移学习，这种方法使用source→pivot和pivot→target的平行语料做预训练，而使用source→target的语料进行微调（<code class="language-plaintext highlighter-rouge">pre-training &amp; fine-tuning</code>）。</p>

    <p><br /></p>
  </li>
</ol>

<h4 id="3">Method</h4>
<h5 id="一般模式">一般模式</h5>

<p>首先先看看一般的pivot-based迁移学习的模式。</p>

<p><img src="http://0.0.0.0:4000/images/p4-pic1.png" alt="img" class="center-image" /><em>普通的迁移学习</em></p>

<p>训练source→pivot，pivot→target的模型，然后用对应的参数初始化source encoder和target decoder，再用(low resource)或者不用(zero-shot)source→target的语料继续训练模型。</p>

<p>在这里的时候，我想起了最初把迁移学习应用在机器翻译领域的那篇文章Zoph所提到的方法并不是这样，根据回顾可以大概做出以下推断：</p>

<p>Zoph的可能比较早了，和他文中提到的普通模型都不一样，Zoph是高资源-&gt;target，copy encoder参数到低资源-&gt;target模型，再用少量的平行语料训练。</p>

<p>而这种pivot based主要思路可能是做zero-shot属于平行语料真的很少以及没有。</p>

<hr />

<p>之后作者就提出了自己的方法，针对如何解决source→pivot,以及pivot→target直接的不一致性。</p>

<p>看了上一篇论文的话会觉得这篇论文提出的这些方法，本质上还是在解决pivot model参数的过程中，source和pivot的语义空间不匹配的问题。作者提出了三种方法，不全是应用在预训练阶段。</p>

<h5 id="阶梯式的预训练">阶梯式的预训练</h5>

<p><img src="http://0.0.0.0:4000/images/p4-pic2.png" alt="img" class="center-image" /><em>阶梯式的预训练</em></p>

<ol>
  <li>训练source→pivot的nmt</li>
  <li>copy 1中encoder的参数，用pivot→target的语料训练模型<br />
利用了联合词典训练source和pivot</li>
</ol>

<p>在拷贝参数的方面来说这种方法与一般模式相比使得source encoder和pivot encoder建立了联系。</p>

<h5 id="枢适配器pivot-adapter">枢适配器(Pivot Adapter)</h5>

<ol>
  <li>
    <p>用source→pivot的模型encode source的句子</p>
  </li>
  <li>用pivot→target的模型encode pivot的句子</li>
  <li>池化，训练一个映射M，将source和pivot的表示映射到一个空间</li>
  <li>通过M，用source和target的语料训练模型</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">如果是zero-shot可能就用不了这个方法了吧</code></p>

<h5 id="跨语言编码器">跨语言编码器</h5>

<p>通过修改source→pivot的训练过程使得encoder拥有跨语言的性能。也就是同时也用pivot做输入训练模型，但当然不能直接输入，而是运用了去噪自编码器的思想，将原始的句子加入了噪声。</p>

<hr />

<p>总的来说：</p>

<ul>
  <li>跨语言编码器对Pre-train阶段的Encoder做了优化。</li>
  <li>阶梯式的预训练对Pre-train阶段的Decoder做了优化。</li>
  <li>枢适配器是对训练过程进行优化。</li>
</ul>

<p><br /></p>

<h4 id="4">实验</h4>
<blockquote>
  <p>PreProcessing &amp; Configuration</p>
</blockquote>

<ul>
  <li>英语作为pivot language</li>
  <li>用Moses对所有语料进行了分词和true-casing(将单词转换为最有可能的原型)。</li>
  <li>每种语言32K的BPE，训练跨语言encoder时使用的是joint BPE</li>
  <li>训练的模型为6层的Transformer</li>
</ul>

<blockquote>
  <p>性能 - Low Resource的情况</p>
</blockquote>

<p><img src="http://0.0.0.0:4000/images/p4-table1.png" alt="img" class="center-image" /><em>结果</em></p>

<ul>
  <li>
    <p>多语言的训练方式比单独的encoder、decoder训练的成果要好</p>
  </li>
  <li>
    <p>Many-to-many 比 many-to-one的效果要好</p>
  </li>
  <li>
    <p>plain transfer对比直接训练提升很大，pivot adapter更是使其获得了更大的性能提升</p>
  </li>
  <li>
    <p>跨语言的encoder的预训练没什么用，和plain transfer没差多少，加了Pivot adapter后效果提升。</p>

    <p>作者认为是跨语言的encoder需要更多的数据去为新的decoder做fine-tune，而且encoder的两种语言也分隔的很开（<code class="language-plaintext highlighter-rouge">不是很懂，不是joint training吗</code>），而pivot adapter直接缩小了两种语言的差距，并且decoder都是同一个（<code class="language-plaintext highlighter-rouge">训练pivot adpter用的是source→pivot的双语语料，比较多，效果合理</code>）。</p>
  </li>
  <li>
    <p>阶梯式训练的提升最大（+1.2%BLEU），加了跨语言encoder后提升更高。</p>
  </li>
</ul>

<p>Pivot adapter由于在encoder和decoder中加了一层，所以并不适合将其添加进阶梯式训练中，因为阶梯式训练的decoder已经和pre-train阶段的encoder训练好了，加入pivot adapter反而有害性能。</p>

<blockquote>
  <p>性能 - Zero-shot的情况</p>
</blockquote>

<p><img src="http://0.0.0.0:4000/images/p4-table2.png" alt="img" class="center-image" /><em>结果</em></p>

<ul>
  <li>
    <p>Plain transfer几乎玩完</p>
  </li>
  <li>
    <p>阶梯式训练有效地解决了plain transfer的痛点(decoder已经train过一遍)，加入跨语言encoder后效果也得到了提升，作者又引入了Chen（<code class="language-plaintext highlighter-rouge">之后看这个</code>）提出的teacher-student模型，效果得到了更大的提升。</p>

    <p>（<code class="language-plaintext highlighter-rouge">这引入teacher-student之后效果和low-resource的不相上下，既然如此为什么不在之前的实验中加入这个方式？</code>）</p>
  </li>
</ul>

<blockquote>
  <p>性能 - 大规模数据的情景</p>
</blockquote>

<p>拥有更多的真实source→target以及合成的source→target语料。</p>

<p><img src="http://0.0.0.0:4000/images/p4-table3.png" alt="img" class="center-image" /><em>结果</em></p>

<ul>
  <li>Plain transfer挺厉害</li>
  <li>作者的方法提升不大，因为语料充足的时候，作者认为plain transfer已经达到了不错的fine-tune效果。</li>
</ul>

<p><br /></p>

<h4 id="5">结论与贡献</h4>
<p>作者主要提出了三种方法，在NMT中能够使基于pivot的tranfer Learning方法取得更好的效果。</p>

<blockquote>
  <p><strong>思考</strong></p>
</blockquote>

<ol>
  <li>
    <p>作者对几种pivot相关的方法，什么是间接模型什么是直接模型讲得很清楚的，图也很直观。对pivot-based model trainning的解释总结也很到位。</p>
  </li>
  <li>
    <p>可能可以用到中文里，如果是pivot adaptor和阶梯式预训练的话应该也不需要字符集统一吧。</p>
  </li>
</ol>

:ET