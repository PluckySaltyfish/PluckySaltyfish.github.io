---
layout: post
title: "嘿,Siri：基于设备神经网络驱动语音触发器的苹果个人助理"
date: 2017-10-22 04:49:18
description: 苹果发布的如何实现“嘿，Siri”的随时唤醒功能。
tags:
 - Machine learning
 - 翻译
---
> 本文翻译自[Apple Machine Learning Journal](https://machinelearning.apple.com/2017/10/01/hey-siri.html)
{: .note}

>“嘿，Siri”功能，让用户不用按键就可以唤醒语音助手Siri。这是因为苹果的处理器集成了非常小的语音识别装置，这个装置一直保持运行，等待着用户说出“嘿，Siri”。当它检测到用户说出这两个词后，Siri将会将后面的语音处理为命令或者查询。“嘿Siri”检测使用深层神经网络（Deep Neural Network ，简称DNN），将每个时刻的声音模型转换成语音的概率分布，并使用时间集成来计算这个声音是“嘿，Siri”的置信度。如果置信度分数足够高，Siri就将被唤醒。本文介绍一些实现此功能的基础技术，主要面向了解一些机器学习，但对语言识别没有了解的读者。

#### 不用手就唤醒Siri
当你需要Siri帮助的时候，不需按键，仅仅说出“嘿Siri”就可以唤醒Siri。这一功能看上去简单，但想快速高效地唤醒Siri，是需要花不少功夫的。“嘿Siri”通过软件，硬件，网络服务高效结合工作，以给用户提供一个良好的体验。

![img]({{ site.baseurl | prepend:site.url}}/images/siri1.png){: .center-image }*图1.iPhone上的嘿Siri流程图*

当你手头正忙的时候————比如当你正在做饭，正在开车，或者正在使用Apple Watch的时候，不用按键就可以使用Siri是一件非常有用的事。如图1所示，整套系统被分为图上的那几个部分。Siri的大部分功能在云端实现，包括主要的自动语音识别，自然语言解释和各种信息服务。在云端，同时也有可以为检测器使用的声学模型提供更新的服务器。本文主要介绍在本地设备（例如iPhone或Apple Watch）上运行的部分，。并且主要介绍检测器：一个专门的持续接受外界声音语音识别器，一旦接受到“Heu，Siri”就会被唤醒。（在最近发布的iPhone上，启用“嘿Siri”功能便可使用）。

#### 检测器：聆听“嘿Siri”
iPhone或者Apple Watch的内置麦克风以每秒16000次的速度将你的声音转换成瞬时声波样本。在频谱分析阶段，这些声波样本流将会被转化成帧序列，每一帧用来描述大约0.01秒的声谱。



