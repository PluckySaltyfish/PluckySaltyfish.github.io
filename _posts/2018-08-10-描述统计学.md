---
layout: post
title: "统计学在机器学习中的应用"
date: 2018-08-11 16:56:11
description: 课程笔记
tags: 
 - 统计学
 - 机器学习
---
### 描述统计学

综合概括分析客观现象的规律性数量特征

![img]({{ site.baseurl | prepend:site.url}}/images/s1.png){: .center-image }*分类*

#### 集中趋势

集中趋势：一组数据向其中心靠拢的倾向和程度。

寻找水平代表值或中心值。

- ##### 均值（Mean）

  定义:指在一组数据之中数据之和再处于数据个数，反应数据集中趋势的一项指标。

  **python实现**

  ```python
  a = np.array([1,2,3,4,5])
  a.mean()#3.5 
  b = np.array([[1,2],[2,3],[3,4],[4,5]])
  b.mean(axis=1) #第二维的均值
  ```

- **中位数（Median）**

  定义：有限数集中排序后，位于中间的数叫做中位数。（偶数个取中间两个数的平均）

  **python实现**

  ```python
  a = np.array([1,2,3,4,5])
  np.median(a) #3.0
  a = np.array([4,2,4,1])
  np.median(a) #3.0
  ```

- **众数（Mode）**

  定义：一组数据中出现次数最多的数值。

  - 存在多个众数的情况：1 2 2 3 3 中众数是2和3
  - 存在无众数的情况：1 2 3 4 5中没有众数
  - 可以应用于非数值型数据

  **python实现**

  ```python
  def mymode(x):
      x = np.array(x)
      count = [np.sum(x==i) for i in set(x.flat)]
      max_count = np.max(count)
      y = [i for i in set(x.flat) if np.sum(x==i)==max_count]
      if len(y)==len(x.flat):
          return []
      return y
  ```

  

  ![img]({{ site.baseurl | prepend:site.url}}/images/statistics_adv.png){: .center-image }*优缺点*

### 推断统计学

根据样本数据推断总体数据特征，对统计总体的未知数量特征做推断

### 泛化误差

`x`：测试的样本

`f(x;D)`：由训练集D学得的模型f对x的预测输出

`y`：真实的输出

算法的平方预测误差期望为：


$$
Err(x) = [(y-f(x:D))^{2}]
$$


学习算法f对测试样本的期望预测为：


$$
\bar{f}(x)=E_{D}[f(x;D)]
$$


也就是针对不同数据集D，f对x的预测值取其期望。

#### 方差（Virance）

反应一组数据的离散程度。

使用样本数相同的不同训练集产生的方差为：


$$
Var(x)=[E_D[(f(x;D)-\bar{f}(x))^{2}]]
$$


度量同样大小的训练集的变动所导致的学习性能的变化，`刻画了数据扰动所造成的影响`。

#### 偏差（Bias）

期望预测与真实标记间的误差成为偏差，为了方便取平方。


$$
bias^{2}(x)=[\bar{f}(x)-y]^{2}
$$


偏差度量了学习算法的预测与真实结果的偏离，`即刻画了学习算法本身的拟合能力`。

#### 噪声

真实标记与数据集中的实际标记间的偏差，不可避免，来自于所取数据


$$
\varepsilon^{2} = E_D[(y_D-y)^{2}]
$$


表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，`刻画了学习问题本身的难度`

![img]({{ site.baseurl | prepend:site.url}}/images/fhwc.png){: .center-image }*泛化误差的三个组成*

- 欠拟合：方差小，偏差大

  模型太过简单（处理办法：加特征或换成更为复杂的模型）

- 过拟合：方差大，偏差小

  出现在充分训练后，拟合能力很强，但模型不具有普适性，轻微的数据扰动都会使学习器发生显著的变化。（处理办法：增加训练数据，降维）

#### 偏差和方差的关系

![img]({{ site.baseurl | prepend:site.url}}/images/fhwc_chart.png){: .center-image }*减少方差和偏差不可兼得*

### 离散程度

衡量指标：极差，方差

**极差**

数据集中最大值减去最小值

**python实现**

```python
a = np.array([1,2,3,4,5])
np.max(a)-np.min(a)#4
```



**方差**

描述数据集中的每一个值与中心值的差异


$$
\sigma^{2} = \frac{1}{N}\sum_{i=1}^N(X_i-\mu)^{2}
$$


​	$$x_i $$代表第i个数据的观察值，$$\mu$$代表数据集的均值

​	

​	**python实现**

```python
np.var(a)
```

### 偏态（skewness）

定义：数据分布的不对称性称为偏态。

偏态系数计算：


$$
SK = \frac{n}{(n-1)(n-2)}\sum(\frac{x_i-\bar{x}}{s})^{3}
$$


s为标准差，除以标准差是为了不同组数据之间也能进行比较。

![img]({{ site.baseurl | prepend:site.url}}/images/skewness.png){: .center-image }*偏态*

**python实现**

```python
import pandas as pd
from pandas import Series
a = Series[1,2,3,4,5]
a.skew()#0.0
```



### 峰度（Kurtosis）

数据分布的扁平或尖峰的程度。

峰度系数K计算：


$$
K=\frac{n(n+1)}{(n-1)(n-2)(n-3)}\sum(\frac{x_i-\bar{x}}{s})^4-\frac{3(n-1)^2}{(n-2)(n-3)}
$$


![img]({{ site.baseurl | prepend:site.url}}/images/kurtosis.png){: .center-image }*峰度*



**python实现**

```python
import pandas as pd
from pandas import Series
a = Series[1,1,3,4,5]
a.kurt()#-2.3242187500000018
```



